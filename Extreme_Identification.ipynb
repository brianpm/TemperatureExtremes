{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme temperature identification\n",
    "\n",
    "This notebook contains working notes and code to identify T extremes.\n",
    "\n",
    "My goal is to develop methods that will identify extremes, and then be able to compute various facets of extreme events, such as duration and magnitude.\n",
    "\n",
    "## Quantile computation\n",
    "\n",
    "The Xarray quantile method currently does not support dask arrays. That means that the calculation of quantiles has to be done on an in-memory DataArray/NumpyArray. I suspect that the implementation of quantile uses numpy's nanpercentile for the calculation. This is known to be slow because it does a 1d calculation looped over all points [https://krstn.eu/np.nanpercentile()-there-has-to-be-a-faster-way/]. \n",
    "\n",
    "Instead of implementing something complicated, we can just do the computation and wait it out, and save the result in a file for later use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39246\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>9</li>\n",
       "  <li><b>Cores: </b>72</li>\n",
       "  <li><b>Memory: </b>405.33 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:39246' processes=9 cores=72>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__aenter__',\n",
       " '__aexit__',\n",
       " '__await__',\n",
       " '__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_asynchronous',\n",
       " '_cancel',\n",
       " '_close',\n",
       " '_connecting_to_scheduler',\n",
       " '_dec_ref',\n",
       " '_deserializers',\n",
       " '_ensure_connected',\n",
       " '_expand_key',\n",
       " '_expand_resources',\n",
       " '_expand_retries',\n",
       " '_gather',\n",
       " '_gather_future',\n",
       " '_gather_keys',\n",
       " '_gather_remote',\n",
       " '_gather_semaphore',\n",
       " '_get_dataset',\n",
       " '_get_futures_error',\n",
       " '_get_task_stream',\n",
       " '_graph_to_futures',\n",
       " '_handle_cancelled_key',\n",
       " '_handle_error',\n",
       " '_handle_key_in_memory',\n",
       " '_handle_lost_data',\n",
       " '_handle_report',\n",
       " '_handle_restart',\n",
       " '_handle_retried_key',\n",
       " '_handle_scheduler_coroutine',\n",
       " '_handle_task_erred',\n",
       " '_heartbeat',\n",
       " '_inc_ref',\n",
       " '_loop_runner',\n",
       " '_optimize_insert_futures',\n",
       " '_pending_msg_buffer',\n",
       " '_periodic_callbacks',\n",
       " '_profile',\n",
       " '_publish_dataset',\n",
       " '_rebalance',\n",
       " '_reconnect',\n",
       " '_recreate_error_locally',\n",
       " '_refcount_lock',\n",
       " '_register_worker_callbacks',\n",
       " '_release_key',\n",
       " '_replicate',\n",
       " '_repr_html_',\n",
       " '_restart',\n",
       " '_retry',\n",
       " '_run',\n",
       " '_run_on_scheduler',\n",
       " '_scatter',\n",
       " '_scheduler_identity',\n",
       " '_send_to_scheduler',\n",
       " '_send_to_scheduler_safe',\n",
       " '_serializers',\n",
       " '_set_config',\n",
       " '_should_close_loop',\n",
       " '_shutdown',\n",
       " '_start',\n",
       " '_start_arg',\n",
       " '_start_ipython_workers',\n",
       " '_startup_kwargs',\n",
       " '_state_handlers',\n",
       " '_stream_handlers',\n",
       " '_threaded_gather',\n",
       " '_threaded_map',\n",
       " '_threaded_scatter',\n",
       " '_timeout',\n",
       " '_update_scheduler_info',\n",
       " '_upload_environment',\n",
       " '_upload_file',\n",
       " '_upload_large_file',\n",
       " 'asynchronous',\n",
       " 'call_stack',\n",
       " 'cancel',\n",
       " 'close',\n",
       " 'cluster',\n",
       " 'collections_to_dsk',\n",
       " 'compute',\n",
       " 'connection_args',\n",
       " 'coroutines',\n",
       " 'current',\n",
       " 'datasets',\n",
       " 'direct_to_workers',\n",
       " 'extensions',\n",
       " 'futures',\n",
       " 'futures_of',\n",
       " 'gather',\n",
       " 'generation',\n",
       " 'get',\n",
       " 'get_dataset',\n",
       " 'get_executor',\n",
       " 'get_futures_error',\n",
       " 'get_metadata',\n",
       " 'get_restrictions',\n",
       " 'get_scheduler_logs',\n",
       " 'get_task_stream',\n",
       " 'get_versions',\n",
       " 'get_worker_logs',\n",
       " 'has_what',\n",
       " 'id',\n",
       " 'io_loop',\n",
       " 'list_datasets',\n",
       " 'loop',\n",
       " 'map',\n",
       " 'nbytes',\n",
       " 'ncores',\n",
       " 'normalize_collection',\n",
       " 'persist',\n",
       " 'processing',\n",
       " 'profile',\n",
       " 'publish_dataset',\n",
       " 'rebalance',\n",
       " 'recreate_error_locally',\n",
       " 'refcount',\n",
       " 'register_worker_callbacks',\n",
       " 'replicate',\n",
       " 'restart',\n",
       " 'retire_workers',\n",
       " 'retry',\n",
       " 'rpc',\n",
       " 'run',\n",
       " 'run_coroutine',\n",
       " 'run_on_scheduler',\n",
       " 'scatter',\n",
       " 'scheduler',\n",
       " 'scheduler_comm',\n",
       " 'scheduler_file',\n",
       " 'scheduler_info',\n",
       " 'security',\n",
       " 'set_metadata',\n",
       " 'shutdown',\n",
       " 'start',\n",
       " 'start_ipython',\n",
       " 'start_ipython_scheduler',\n",
       " 'start_ipython_workers',\n",
       " 'status',\n",
       " 'submit',\n",
       " 'sync',\n",
       " 'unpublish_dataset',\n",
       " 'upload_environment',\n",
       " 'upload_file',\n",
       " 'who_has',\n",
       " 'write_scheduler_file']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'tmax' (time: 14736, lat: 360, lon: 720)>\n",
      "dask.array<shape=(14736, 360, 720), dtype=float32, chunksize=(365, 360, 720)>\n",
      "Coordinates:\n",
      "  * lat      (lat) float32 89.75 89.25 88.75 88.25 ... -88.75 -89.25 -89.75\n",
      "  * lon      (lon) float32 0.25 0.75 1.25 1.75 ... 358.25 358.75 359.25 359.75\n",
      "  * time     (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2019-05-06\n",
      "Attributes:\n",
      "    level_desc:    Surface\n",
      "    statistic:     Mean\n",
      "    parent_stat:   Other\n",
      "    long_name:     Daily Maximum Temperature\n",
      "    cell_methods:  time: mean\n",
      "    valid_range:   [-90.  50.]\n",
      "    avg_period:    0000-00-01 00:00:00\n",
      "    dataset:       CPC Global Temperature\n",
      "    comments:      GTS data and is gridded using the Shepard Algorithm\n",
      "    max_period:    6z to 6z\n",
      "    units:         degC\n",
      "    var_desc:      Maximum Temperature\n",
      "CPU times: user 980 ms, sys: 170 ms, total: 1.15 s\n",
      "Wall time: 2.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = xr.open_mfdataset(\"/project/amp/jcaron/CPC_Tminmax/tmax.*.nc\")\n",
    "tmax = ds['tmax']\n",
    "print(tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# what is the median value for each day\n",
    "# tmax_median_by_day = xr.ufuncs.median(tmax.groupby('time.dayofyear'), dim='time')\n",
    "# tmax_median_by_day.sel(lat=55, lon=83, method='nearest').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 s, sys: 25 s, total: 38.3 s\n",
      "Wall time: 44.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'tmax' (time: 14736, lat: 360, lon: 720)>\n",
       "array([[[nan, nan, ..., nan, nan],\n",
       "        [nan, nan, ..., nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, ..., nan, nan],\n",
       "        [nan, nan, ..., nan, nan]],\n",
       "\n",
       "       [[nan, nan, ..., nan, nan],\n",
       "        [nan, nan, ..., nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, ..., nan, nan],\n",
       "        [nan, nan, ..., nan, nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[nan, nan, ..., nan, nan],\n",
       "        [nan, nan, ..., nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, ..., nan, nan],\n",
       "        [nan, nan, ..., nan, nan]],\n",
       "\n",
       "       [[nan, nan, ..., nan, nan],\n",
       "        [nan, nan, ..., nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, ..., nan, nan],\n",
       "        [nan, nan, ..., nan, nan]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 89.75 89.25 88.75 88.25 ... -88.75 -89.25 -89.75\n",
       "  * lon      (lon) float32 0.25 0.75 1.25 1.75 ... 358.25 358.75 359.25 359.75\n",
       "  * time     (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2019-05-06\n",
       "Attributes:\n",
       "    level_desc:    Surface\n",
       "    statistic:     Mean\n",
       "    parent_stat:   Other\n",
       "    long_name:     Daily Maximum Temperature\n",
       "    cell_methods:  time: mean\n",
       "    valid_range:   [-90.  50.]\n",
       "    avg_period:    0000-00-01 00:00:00\n",
       "    dataset:       CPC Global Temperature\n",
       "    comments:      GTS data and is gridded using the Shepard Algorithm\n",
       "    max_period:    6z to 6z\n",
       "    units:         degC\n",
       "    var_desc:      Maximum Temperature"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tmax.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.2 ms, sys: 947 Âµs, total: 24.1 ms\n",
      "Wall time: 20.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grp = tmax.groupby('time.dayofyear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1354: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input, interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 1min 23s, sys: 7min 43s, total: 1h 9min 7s\n",
      "Wall time: 1h 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the 90th percentile\n",
    "tmax_90_by_day = grp.apply(xr.DataArray.quantile, args=(.9,), **{'dim':'time', 'interpolation':'linear', 'keep_attrs':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_90_by_day.name = \"tmax90pct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_90_by_day.to_netcdf(\"/project/amp/brianpm/TemperatureExtremes/Derived/CPC_tmax_90pct_dayofyear.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## thoughts on this approach\n",
    "\n",
    "I like this Xarray approach because it works in one line. The obvious downside is that it is unreasonably slow.\n",
    "\n",
    "In our next step, we probably want to gather days on either side of each day to increase sample size. In Xarray, we can definitely do that by using a rolling operation, but that would need to be separate from the groupby operation, I think. \n",
    "\n",
    "Probably the easiest option is to deal with the time sampling in a loop. Then there's a question of speed. Is it worth breaking the quantile calculation into a loop and spreading it out using multiprocessing, or just wait it out without having to deal with setting up a pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'tmax' (time: 14736)>\n",
       "array([14.950293, 16.44022 , 19.941858, ..., 20.553688, 20.05624 , 22.033697],\n",
       "      dtype=float32)\n",
       "Coordinates:\n",
       "    lat      float32 39.75\n",
       "    lon      float32 50.25\n",
       "  * time     (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2019-05-06\n",
       "Attributes:\n",
       "    level_desc:    Surface\n",
       "    statistic:     Mean\n",
       "    parent_stat:   Other\n",
       "    long_name:     Daily Maximum Temperature\n",
       "    cell_methods:  time: mean\n",
       "    valid_range:   [-90.  50.]\n",
       "    avg_period:    0000-00-01 00:00:00\n",
       "    dataset:       CPC Global Temperature\n",
       "    comments:      GTS data and is gridded using the Shepard Algorithm\n",
       "    max_period:    6z to 6z\n",
       "    units:         degC\n",
       "    var_desc:      Maximum Temperature"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmax_pt = tmax[:,100,100]\n",
    "tmax_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dict(tmax_pt.groupby(\"time.dayofyear\"))  # this is kind of a kludge, but gives keys 1-366, with values that are dataArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_by_day = dict(tmax.groupby(\"time.dayofyear\"))  # this is kind of a kludge, but gives keys 1-366, with values that are dataArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_90th_by_day = {k:np.nanquantile(tmax_by_day[k], 0.9, axis=0) for k in tmax_by_day}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "quantile does not work for arrays stored as dask arrays. Load the data via .compute() or .load() prior to calling this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, shortcut, args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m         applied = (maybe_wrap_array(arr, func(arr, *args, **kwargs))\n\u001b[1;32m    557\u001b[0m                    for arr in grouped)\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/groupby.py\u001b[0m in \u001b[0;36m_combine\u001b[0;34m(self, applied, shortcut)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;34m\"\"\"Recombine the applied objects like the original.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mapplied_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeek_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_concat_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/utils.py\u001b[0m in \u001b[0;36mpeek_at\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m    138\u001b[0m     \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/groupby.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_grouped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         applied = (maybe_wrap_array(arr, func(arr, *args, **kwargs))\n\u001b[0;32m--> 557\u001b[0;31m                    for arr in grouped)\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36mquantile\u001b[0;34m(self, q, dim, interpolation, keep_attrs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m         ds = self._to_temp_dataset().quantile(\n\u001b[0;32m-> 2362\u001b[0;31m             q, dim=dim, keep_attrs=keep_attrs, interpolation=interpolation)\n\u001b[0m\u001b[1;32m   2363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_temp_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mquantile\u001b[0;34m(self, q, dim, interpolation, numeric_only, keep_attrs)\u001b[0m\n\u001b[1;32m   3980\u001b[0m                             \u001b[0mreduce_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3981\u001b[0m                         variables[name] = var.quantile(\n\u001b[0;32m-> 3982\u001b[0;31m                             q, dim=reduce_dims, interpolation=interpolation)\n\u001b[0m\u001b[1;32m   3983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3984\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mquantile\u001b[0;34m(self, q, dim, interpolation)\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \"\"\"\n\u001b[1;32m   1544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdask_array_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m             raise TypeError(\"quantile does not work for arrays stored as dask \"\n\u001b[0m\u001b[1;32m   1546\u001b[0m                             \u001b[0;34m\"arrays. Load the data via .compute() or .load() \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m                             \"prior to calling this method.\")\n",
      "\u001b[0;31mTypeError\u001b[0m: quantile does not work for arrays stored as dask arrays. Load the data via .compute() or .load() prior to calling this method."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this is probably the same as above, but now we'll get a better data structure out of it.\n",
    "# Slow when applied to the whole dataset.\n",
    "tmax_90_by_day_2 = tmax.groupby('time.dayofyear').apply(xr.DataArray.quantile, args=(.9,), **{'dim':'time', 'interpolation':'linear', 'keep_attrs':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to put a window around each day to increase the sample size and smooth the quantile time series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "applied function returned data with unexpected number of dimensions: 0 vs 2, for dimensions ('lat', 'lon')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5e3cd1a740f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_ufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetquant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_core_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/computation.py\u001b[0m in \u001b[0;36mapply_ufunc\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    972\u001b[0m                                        \u001b[0mkeep_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                                        dask=dask)\n\u001b[0;32m--> 974\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_groupby_ufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         return apply_dataset_ufunc(variables_ufunc, *args,\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/computation.py\u001b[0m in \u001b[0;36mapply_groupby_ufunc\u001b[0;34m(func, *args)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mzipped_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mzipped_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0mapplied_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeek_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0mcombine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_groupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/utils.py\u001b[0m in \u001b[0;36mpeek_at\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \"\"\"\n\u001b[1;32m    139\u001b[0m     \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/computation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0miterators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mzipped_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mzipped_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0mapplied_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeek_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0mcombine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_groupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/computation.py\u001b[0m in \u001b[0;36mapply_ufunc\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m                                      \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m                                      \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m                                      exclude_dims=exclude_dims)\n\u001b[0m\u001b[1;32m    988\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariables_ufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/computation.py\u001b[0m in \u001b[0;36mapply_dataarray_ufunc\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mdata_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'variable'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mresult_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_outputs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/computation.py\u001b[0m in \u001b[0;36mapply_variable_ufunc\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;34m'applied function returned data with unexpected '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0;34m'number of dimensions: {} vs {}, for dimensions {}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 .format(data.ndim, len(dims), dims))\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: applied function returned data with unexpected number of dimensions: 0 vs 2, for dimensions ('lat', 'lon')"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_ufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "apply_ufunc(func : Callable,\n",
       "               *args : Any,\n",
       "               input_core_dims : Optional[Sequence[Sequence]] = None,\n",
       "               output_core_dims : Optional[Sequence[Sequence]] = ((),),\n",
       "               exclude_dims : Collection = frozenset(),\n",
       "               vectorize : bool = False,\n",
       "               join : str = 'exact',\n",
       "               dataset_join : str = 'exact',\n",
       "               dataset_fill_value : Any = _NO_FILL_VALUE,\n",
       "               keep_attrs : bool = False,\n",
       "               kwargs : Mapping = None,\n",
       "               dask : str = 'forbidden',\n",
       "               output_dtypes : Optional[Sequence] = None,\n",
       "               output_sizes : Optional[Mapping[Any, int]] = None)\n",
       "\n",
       "Apply a vectorized function for unlabeled arrays on xarray objects.\n",
       "\n",
       "The function will be mapped over the data variable(s) of the input\n",
       "arguments using xarray's standard rules for labeled computation, including\n",
       "alignment, broadcasting, looping over GroupBy/Dataset variables, and\n",
       "merging of coordinates.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "func : callable\n",
       "    Function to call like ``func(*args, **kwargs)`` on unlabeled arrays\n",
       "    (``.data``) that returns an array or tuple of arrays. If multiple\n",
       "    arguments with non-matching dimensions are supplied, this function is\n",
       "    expected to vectorize (broadcast) over axes of positional arguments in\n",
       "    the style of NumPy universal functions [1]_ (if this is not the case,\n",
       "    set ``vectorize=True``). If this function returns multiple outputs, you\n",
       "    must set ``output_core_dims`` as well.\n",
       "*args : Dataset, DataArray, GroupBy, Variable, numpy/dask arrays or scalars\n",
       "    Mix of labeled and/or unlabeled arrays to which to apply the function.\n",
       "input_core_dims : Sequence[Sequence], optional\n",
       "    List of the same length as ``args`` giving the list of core dimensions\n",
       "    on each input argument that should not be broadcast. By default, we\n",
       "    assume there are no core dimensions on any input arguments.\n",
       "\n",
       "    For example, ``input_core_dims=[[], ['time']]`` indicates that all\n",
       "    dimensions on the first argument and all dimensions other than 'time'\n",
       "    on the second argument should be broadcast.\n",
       "\n",
       "    Core dimensions are automatically moved to the last axes of input\n",
       "    variables before applying ``func``, which facilitates using NumPy style\n",
       "    generalized ufuncs [2]_.\n",
       "output_core_dims : List[tuple], optional\n",
       "    List of the same length as the number of output arguments from\n",
       "    ``func``, giving the list of core dimensions on each output that were\n",
       "    not broadcast on the inputs. By default, we assume that ``func``\n",
       "    outputs exactly one array, with axes corresponding to each broadcast\n",
       "    dimension.\n",
       "\n",
       "    Core dimensions are assumed to appear as the last dimensions of each\n",
       "    output in the provided order.\n",
       "exclude_dims : set, optional\n",
       "    Core dimensions on the inputs to exclude from alignment and\n",
       "    broadcasting entirely. Any input coordinates along these dimensions\n",
       "    will be dropped. Each excluded dimension must also appear in\n",
       "    ``input_core_dims`` for at least one argument. Only dimensions listed\n",
       "    here are allowed to change size between input and output objects.\n",
       "vectorize : bool, optional\n",
       "    If True, then assume ``func`` only takes arrays defined over core\n",
       "    dimensions as input and vectorize it automatically with\n",
       "    :py:func:`numpy.vectorize`. This option exists for convenience, but is\n",
       "    almost always slower than supplying a pre-vectorized function.\n",
       "    Using this option requires NumPy version 1.12 or newer.\n",
       "join : {'outer', 'inner', 'left', 'right', 'exact'}, optional\n",
       "    Method for joining the indexes of the passed objects along each\n",
       "    dimension, and the variables of Dataset objects with mismatched\n",
       "    data variables:\n",
       "\n",
       "    - 'outer': use the union of object indexes\n",
       "    - 'inner': use the intersection of object indexes\n",
       "    - 'left': use indexes from the first object with each dimension\n",
       "    - 'right': use indexes from the last object with each dimension\n",
       "    - 'exact': raise `ValueError` instead of aligning when indexes to be\n",
       "      aligned are not equal\n",
       "dataset_join : {'outer', 'inner', 'left', 'right', 'exact'}, optional\n",
       "    Method for joining variables of Dataset objects with mismatched\n",
       "    data variables.\n",
       "\n",
       "    - 'outer': take variables from both Dataset objects\n",
       "    - 'inner': take only overlapped variables\n",
       "    - 'left': take only variables from the first object\n",
       "    - 'right': take only variables from the last object\n",
       "    - 'exact': data variables on all Dataset objects must match exactly\n",
       "dataset_fill_value : optional\n",
       "    Value used in place of missing variables on Dataset inputs when the\n",
       "    datasets do not share the exact same ``data_vars``. Required if\n",
       "    ``dataset_join not in {'inner', 'exact'}``, otherwise ignored.\n",
       "keep_attrs: boolean, Optional\n",
       "    Whether to copy attributes from the first argument to the output.\n",
       "kwargs: dict, optional\n",
       "    Optional keyword arguments passed directly on to call ``func``.\n",
       "dask: 'forbidden', 'allowed' or 'parallelized', optional\n",
       "    How to handle applying to objects containing lazy data in the form of\n",
       "    dask arrays:\n",
       "\n",
       "    - 'forbidden' (default): raise an error if a dask array is encountered.\n",
       "    - 'allowed': pass dask arrays directly on to ``func``.\n",
       "    - 'parallelized': automatically parallelize ``func`` if any of the\n",
       "      inputs are a dask array. If used, the ``output_dtypes`` argument must\n",
       "      also be provided. Multiple output arguments are not yet supported.\n",
       "output_dtypes : list of dtypes, optional\n",
       "    Optional list of output dtypes. Only used if dask='parallelized'.\n",
       "output_sizes : dict, optional\n",
       "    Optional mapping from dimension names to sizes for outputs. Only used\n",
       "    if dask='parallelized' and new dimensions (not found on inputs) appear\n",
       "    on outputs.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "Single value or tuple of Dataset, DataArray, Variable, dask.array.Array or\n",
       "numpy.ndarray, the first type on that list to appear on an input.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       "Calculate the vector magnitude of two arguments:\n",
       "\n",
       ">>> def magnitude(a, b):\n",
       "...     func = lambda x, y: np.sqrt(x ** 2 + y ** 2)\n",
       "...     return xr.apply_ufunc(func, a, b)\n",
       "\n",
       "You can now apply ``magnitude()`` to ``xr.DataArray`` and ``xr.Dataset``\n",
       "objects, with automatically preserved dimensions and coordinates, e.g.,\n",
       "\n",
       ">>> array = xr.DataArray([1, 2, 3], coords=[('x', [0.1, 0.2, 0.3])])\n",
       ">>> magnitude(array, -array)\n",
       "<xarray.DataArray (x: 3)>\n",
       "array([1.414214, 2.828427, 4.242641])\n",
       "Coordinates:\n",
       "  * x        (x) float64 0.1 0.2 0.3\n",
       "\n",
       "Plain scalars, numpy arrays and a mix of these with xarray objects is also\n",
       "supported:\n",
       "\n",
       ">>> magnitude(4, 5)\n",
       "5.0\n",
       ">>> magnitude(3, np.array([0, 4]))\n",
       "array([3., 5.])\n",
       ">>> magnitude(array, 0)\n",
       "<xarray.DataArray (x: 3)>\n",
       "array([1., 2., 3.])\n",
       "Coordinates:\n",
       "  * x        (x) float64 0.1 0.2 0.3\n",
       "\n",
       "Other examples of how you could use ``apply_ufunc`` to write functions to\n",
       "(very nearly) replicate existing xarray functionality:\n",
       "\n",
       "Compute the mean (``.mean``) over one dimension::\n",
       "\n",
       "    def mean(obj, dim):\n",
       "        # note: apply always moves core dimensions to the end\n",
       "        return apply_ufunc(np.mean, obj,\n",
       "                           input_core_dims=[[dim]],\n",
       "                           kwargs={'axis': -1})\n",
       "\n",
       "Inner product over a specific dimension (like ``xr.dot``)::\n",
       "\n",
       "    def _inner(x, y):\n",
       "        result = np.matmul(x[..., np.newaxis, :], y[..., :, np.newaxis])\n",
       "        return result[..., 0, 0]\n",
       "\n",
       "    def inner_product(a, b, dim):\n",
       "        return apply_ufunc(_inner, a, b, input_core_dims=[[dim], [dim]])\n",
       "\n",
       "Stack objects along a new dimension (like ``xr.concat``)::\n",
       "\n",
       "    def stack(objects, dim, new_coord):\n",
       "        # note: this version does not stack coordinates\n",
       "        func = lambda *x: np.stack(x, axis=-1)\n",
       "        result = apply_ufunc(func, *objects,\n",
       "                             output_core_dims=[[dim]],\n",
       "                             join='outer',\n",
       "                             dataset_fill_value=np.nan)\n",
       "        result[dim] = new_coord\n",
       "        return result\n",
       "\n",
       "If your function is not vectorized but can be applied only to core\n",
       "dimensions, you can use ``vectorize=True`` to turn into a vectorized\n",
       "function. This wraps :py:func:`numpy.vectorize`, so the operation isn't\n",
       "terribly fast. Here we'll use it to calculate the distance between\n",
       "empirical samples from two probability distributions, using a scipy\n",
       "function that needs to be applied to vectors::\n",
       "\n",
       "    import scipy.stats\n",
       "\n",
       "    def earth_mover_distance(first_samples,\n",
       "                             second_samples,\n",
       "                             dim='ensemble'):\n",
       "        return apply_ufunc(scipy.stats.wasserstein_distance,\n",
       "                           first_samples, second_samples,\n",
       "                           input_core_dims=[[dim], [dim]],\n",
       "                           vectorize=True)\n",
       "\n",
       "Most of NumPy's builtin functions already broadcast their inputs\n",
       "appropriately for use in `apply`. You may find helper functions such as\n",
       "numpy.broadcast_arrays helpful in writing your function. `apply_ufunc` also\n",
       "works well with numba's vectorize and guvectorize. Further explanation with\n",
       "examples are provided in the xarray documentation [3].\n",
       "\n",
       "See also\n",
       "--------\n",
       "numpy.broadcast_arrays\n",
       "numba.vectorize\n",
       "numba.guvectorize\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] http://docs.scipy.org/doc/numpy/reference/ufuncs.html\n",
       ".. [2] http://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html\n",
       ".. [3] http://xarray.pydata.org/en/stable/computation.html#wrapping-custom-computation\n",
       "\u001b[0;31mFile:\u001b[0m      /project/amp/brianpm/miniconda3/lib/python3.7/site-packages/xarray/core/computation.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xr.apply_ufunc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
